{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we will define our model and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "\n",
    "Finally, you should have at least one notebook where you define and train your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.data.utils import save_graphs, load_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn.pytorch import NNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class ElectronConv(nn.Module):\n",
    "    \"\"\"Graph convolution module used by the GraphElectron model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat : int\n",
    "        Input feature size.\n",
    "    out_feat : int\n",
    "        Output feature size.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(ElectronConv, self).__init__()\n",
    "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
    "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        \"\"\"Forward computation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : Graph\n",
    "            The input graph.\n",
    "        h : Tensor\n",
    "            The input node feature.\n",
    "        \"\"\"\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # update_all is a message passing API.\n",
    "            g.update_all(message_func=fn.copy_u('h', 'm'), reduce_func=fn.mean('m', 'h_N'))\n",
    "            h_N = g.ndata['h_N']\n",
    "            h_total = torch.cat([h, h_N], dim=1)\n",
    "            return self.linear(h_total)\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = ElectronConv(in_feats, h_feats)\n",
    "        self.conv2 = ElectronConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN_Rec(nn.Module):\n",
    "    \"\"\"MPNN.\n",
    "\n",
    "    MPNN is introduced in `Neural Message Passing for Quantum Chemistry\n",
    "    <https://arxiv.org/abs/1704.01212>`__.\n",
    "\n",
    "    This class performs message passing in MPNN and returns the updated node representations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_in_feats : int\n",
    "        Size for the input node features.\n",
    "    node_out_feats : int\n",
    "        Size for the output node representations. Default to 64.\n",
    "    edge_in_feats : int\n",
    "        Size for the input edge features. Default to 128.\n",
    "    edge_hidden_feats : int\n",
    "        Size for the hidden edge representations.\n",
    "    num_step_message_passing : int\n",
    "        Number of message passing steps. Default to 6.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in_feats, edge_in_feats, out_dim=1,\n",
    "                 edge_hidden_feats=128, num_step_message_passing=6):\n",
    "        super(MPNN_Rec, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, out_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.num_step_message_passing = num_step_message_passing\n",
    "        edge_network = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(edge_hidden_feats, out_dim * out_dim)\n",
    "        )\n",
    "        self.gnn_layer = NNConv(\n",
    "            in_feats=out_dim,\n",
    "            out_feats=out_dim,\n",
    "            edge_func=edge_network,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "        self.gru = nn.GRU(out_dim, out_dim)\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        \"\"\"Performs message passing and updates node representations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : DGLGraph\n",
    "            DGLGraph for a batch of graphs.\n",
    "        node_feats : float32 tensor of shape (V, node_in_feats)\n",
    "            Input node features. V for the number of nodes in the batch of graphs.\n",
    "        edge_feats : float32 tensor of shape (E, edge_in_feats)\n",
    "            Input edge features. E for the number of edges in the batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node_feats : float32 tensor of shape (V, node_out_feats)\n",
    "            Output node representations.\n",
    "        \"\"\"\n",
    "        node_feats = self.fc1(node_feats) # (V, node_out_feats)\n",
    "        \n",
    "        hidden_feats = node_feats.unsqueeze(0)           # (1, V, node_out_feats)\n",
    "\n",
    "        for _ in range(self.num_step_message_passing):\n",
    "            node_feats = F.relu(self.gnn_layer(g, node_feats, edge_feats))\n",
    "            node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "            node_feats = node_feats.squeeze(0)\n",
    "            \n",
    "        node_feats = self.fc2(node_feats)\n",
    "        \n",
    "        return node_feats.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the graphs to get dimensions for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, _ = load_graphs(\"./DataGraphs/data_F_graph.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 11 (node), 5 (edge)\n"
     ]
    }
   ],
   "source": [
    "# All graphs in the list have the same scheme size, so pull the dimensions from the first\n",
    "node_dim = graphs[0].ndata['atom_feats'].shape[1]\n",
    "edge_dim = graphs[0].edata['bond_feats'].shape[1]\n",
    "print(\"Dimensions:\", node_dim, \"(node),\", edge_dim, \"(edge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MPNN_Rec(node_dim, edge_dim, out_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = graphs[0]\n",
    "edges = sample_data.edata['bond_feats'].float()\n",
    "nodes = sample_data.ndata['atom_feats'].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 torch.Size([42, 11])\n",
      "0 torch.Size([42, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2647, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_data, nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
