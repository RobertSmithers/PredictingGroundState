{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we will define our model and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "\n",
    "Finally, you should have at least one notebook where you define and train your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in /opt/conda/lib/python3.8/site-packages (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "\n",
    "import nbimporter\n",
    "import graphize_data as graphize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn.pytorch import NNConv\n",
    "from dgl.nn.pytorch import GatedGraphConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ronan make your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RJ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to experiment with: SumPooling layer? Kind of like a conv, can sum up neighbors and find important structural properties of molecule\n",
    "# from dgl.nn import SumPooling\n",
    "\n",
    "# Also a good read here (https://arxiv.org/pdf/1710.10370.pdf) on Topology Adaptive Graph Convolutional layer might be useful.\n",
    "# From my takeaways, we can use this \"topology\" to better track/weight the important parts of the structure\n",
    "# (maybe the center of the molecule is important, or specific edge portions of the molecule) TAG can find this\n",
    "\n",
    "# SAGEConv\n",
    "\n",
    "# Ultimately, the NNConv layer, as used in the MPNN model, is the best one for this situation.\n",
    "# We have come to this conclusion after trying various other convolution modules\n",
    "# and finally reading up on this paper which relates closely to what we are doing (https://arxiv.org/pdf/1704.01212.pdf)\n",
    "# (Quantum Chemistry computations)\n",
    "\n",
    "# Note they used GatedGraphConv first and that worked okay but not as well as NNConv... we could look to backtrack to GGC\n",
    "class Electron_MPNN(nn.Module):\n",
    "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=128,\n",
    "                 edge_hidden_feats=256):\n",
    "        super(Electron_MPNN, self).__init__()\n",
    "\n",
    "        # Projection\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, node_out_feats),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        # Multi-iteration Convolution\n",
    "#         self.message_passing_steps = message_passing_steps\n",
    "        edge_func = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats)\n",
    "        )\n",
    "        \n",
    "        self.gnn1 = NNConv(\n",
    "            in_feats=node_out_feats,\n",
    "            out_feats=node_out_feats,\n",
    "            edge_func=edge_func,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "        \n",
    "        self.gnn2 = GatedGraphConv(\n",
    "            in_feats=node_out_feats,\n",
    "            out_feats=node_out_feats,\n",
    "            n_steps=2,\n",
    "            n_etypes=edge_in_feats\n",
    "        )\n",
    "        \n",
    "        # GRU used in MPNN to get rid of vanishing gradient on Conv layer\n",
    "        self.gru = nn.GRU(node_out_feats, node_out_feats)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(out_dim, out_dim)\n",
    "\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        node_feats = self.fc1(node_feats) # (V, node_out_feats)\n",
    "        \n",
    "        hidden_feats = node_feats.unsqueeze(0)           # (1, V, node_out_feats)\n",
    "        \n",
    "        # Conv 1\n",
    "        node_feats = self.gnn1(g, node_feats, edge_feats)\n",
    "        \n",
    "        # GRU requires 3 dimensions\n",
    "        # GRU in between each convolution layer to retain gradient\n",
    "        node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "        node_feats = node_feats.squeeze(0)\n",
    "        \n",
    "        # Conv 2\n",
    "        node_feats = self.gnn2(g, node_feats, edge_feats)\n",
    "        \n",
    "        # Second GRU\n",
    "        node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "        node_feats = node_feats.squeeze(0)\n",
    "    \n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import Set2Set\n",
    "class MPNNPredictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_in_feats,\n",
    "                 edge_in_feats,\n",
    "                 node_out_feats=128,\n",
    "                 edge_hidden_feats=256,\n",
    "                 n_tasks=5,\n",
    "                 num_step_set2set=6,\n",
    "                 num_layer_set2set=3\n",
    "                ):\n",
    "        super(MPNNPredictor, self).__init__()\n",
    "\n",
    "        self.gnn = Electron_MPNN(node_in_feats=node_in_feats,\n",
    "                                 node_out_feats=node_out_feats,\n",
    "                                 edge_in_feats=edge_in_feats,\n",
    "                                 edge_hidden_feats=edge_hidden_feats\n",
    "                                )\n",
    "                    \n",
    "        self.readout = Set2Set(input_dim=node_out_feats,\n",
    "                               n_iters=num_step_set2set,\n",
    "                               n_layers=num_layer_set2set)\n",
    "        \n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(node_out_feats, n_tasks)\n",
    "        )\n",
    "    \n",
    "    def forward(self, g, node_feats=None, edge_feats=None):\n",
    "\n",
    "        # If trying to make a prediction based on smiles object (for evaluation), convert to graph\n",
    "        if isinstance(g, str):\n",
    "\n",
    "            g = graphize.smiles_to_bigraph(g,\n",
    "                                       node_featurizer = graphize.featurize_atoms,\n",
    "                                       edge_featurizer = graphize.featurize_bonds,\n",
    "                                       explicit_hydrogens = True\n",
    "                                 )\n",
    "            edge_feats = g.edata['bond_feats'].float()\n",
    "            node_feats = g.ndata['atom_feats'].float()\n",
    "        \n",
    "\n",
    "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
    "\n",
    "        graph_feats = self.readout(g, node_feats)\n",
    "\n",
    "        return self.predict(graph_feats).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the graphs to get dimensions for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, _ = load_graphs(\"./DataGraphs/data_F_graph.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 11 (node), 5 (edge)\n"
     ]
    }
   ],
   "source": [
    "# All graphs in the list have the same scheme size, so pull the dimensions from the first\n",
    "node_dim = graphs[0].ndata['atom_feats'].shape[1]\n",
    "edge_dim = graphs[0].edata['bond_feats'].shape[1]\n",
    "print(\"Dimensions:\", node_dim, \"(node),\", edge_dim, \"(edge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MPNNPredictor(node_dim, edge_dim)\n",
    "#model = Electron_MPNN(node_dim, edge_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = graphs[3]\n",
    "edges = sample_data.edata['bond_feats'].float()\n",
    "nodes = sample_data.ndata['atom_feats'].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (26x11 and 6x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-735efd2c3315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-2614bac2b36a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, node_feats, edge_feats)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mnode_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mgraph_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-5d36da5f0078>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, node_feats, edge_feats)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mnode_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_feats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (V, node_out_feats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mhidden_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# (1, V, node_out_feats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (26x11 and 6x64)"
     ]
    }
   ],
   "source": [
    "model(sample_data, nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to experiment with: SumPooling layer? Kind of like a conv, can sum up neighbors and find important structural properties of molecule\n",
    "# from dgl.nn import SumPooling\n",
    "\n",
    "# Also a good read here (https://arxiv.org/pdf/1710.10370.pdf) on Topology Adaptive Graph Convolutional layer might be useful.\n",
    "# From my takeaways, we can use this \"topology\" to better track/weight the important parts of the structure\n",
    "# (maybe the center of the molecule is important, or specific edge portions of the molecule) TAG can find this\n",
    "\n",
    "# SAGEConv\n",
    "\n",
    "# Ultimately, the NNConv layer, as used in the MPNN model, is the best one for this situation.\n",
    "# We have come to this conclusion after trying various other convolution modules\n",
    "# and finally reading up on this paper which relates closely to what we are doing (https://arxiv.org/pdf/1704.01212.pdf)\n",
    "# (Quantum Chemistry computations)\n",
    "\n",
    "# Note they used GatedGraphConv first and that worked okay but not as well as NNConv... we could look to backtrack to GGC\n",
    "class Electron_MPNN_old(nn.Module):\n",
    "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=1,\n",
    "                 edge_hidden_feats=128):\n",
    "        super(Electron_MPNN_old, self).__init__()\n",
    "\n",
    "        # Projection\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, node_out_feats),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        # Multi-iteration Convolution\n",
    "#         self.message_passing_steps = message_passing_steps\n",
    "        edge_func = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats)\n",
    "        )\n",
    "        \n",
    "        self.gnn_layer = NNConv(\n",
    "            in_feats=node_out_feats,\n",
    "            out_feats=node_out_feats,\n",
    "            edge_func=edge_func,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "        \n",
    "        # GRU used in MPNN to get rid of vanishing gradient on Conv layer\n",
    "#         self.gru = nn.GRU(node_out_feats, node_out_feats)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(out_dim, out_dim)\n",
    "\n",
    "\n",
    "    def forward(self, g, node_feats=None, edge_feats=None):\n",
    "        # If trying to make a prediction based on smiles object (for evaluation), convert to graph\n",
    "        if isinstance(g, str):\n",
    "            g = graphize.smiles_to_bigraph(g,\n",
    "                                       node_featurizer = graphize.featurize_atoms,\n",
    "                                       edge_featurizer = graphize.featurize_bonds,\n",
    "                                       explicit_hydrogens = True\n",
    "                                 )\n",
    "            edge_feats = g.edata['bond_feats'].float()\n",
    "            node_feats = g.ndata['atom_feats'].float()\n",
    "        \n",
    "        node_feats = self.fc1(node_feats) # (V, node_out_feats)\n",
    "        \n",
    "        hidden_feats = node_feats.unsqueeze(0)           # (1, V, node_out_feats)\n",
    "        \n",
    "        node_feats = self.gnn_layer(g, node_feats, edge_feats)\n",
    "#         node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "#         node_feats = node_feats.squeeze(0)\n",
    "    \n",
    "        return [node_feats.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Electron_MPNN_old(node_dim, edge_dim)\n",
    "model2.load_state_dict(torch.load(\"SavedModels/11.5k_electron_custom.pth\")[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-2862.0132, grad_fn=<MeanBackward0>)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(sample_data, nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1291\n",
      "20 / 1291\n",
      "40 / 1291\n",
      "60 / 1291\n",
      "80 / 1291\n",
      "100 / 1291\n",
      "120 / 1291\n",
      "140 / 1291\n",
      "160 / 1291\n",
      "180 / 1291\n",
      "200 / 1291\n",
      "220 / 1291\n",
      "240 / 1291\n",
      "260 / 1291\n",
      "280 / 1291\n",
      "300 / 1291\n",
      "320 / 1291\n",
      "340 / 1291\n",
      "360 / 1291\n",
      "380 / 1291\n",
      "400 / 1291\n",
      "420 / 1291\n",
      "440 / 1291\n",
      "460 / 1291\n",
      "480 / 1291\n",
      "500 / 1291\n",
      "520 / 1291\n",
      "540 / 1291\n",
      "560 / 1291\n",
      "580 / 1291\n",
      "600 / 1291\n",
      "620 / 1291\n",
      "640 / 1291\n",
      "660 / 1291\n",
      "680 / 1291\n",
      "700 / 1291\n",
      "720 / 1291\n",
      "740 / 1291\n",
      "760 / 1291\n",
      "780 / 1291\n",
      "800 / 1291\n",
      "820 / 1291\n",
      "840 / 1291\n",
      "860 / 1291\n",
      "880 / 1291\n",
      "900 / 1291\n",
      "920 / 1291\n",
      "940 / 1291\n",
      "960 / 1291\n",
      "980 / 1291\n",
      "1000 / 1291\n",
      "1020 / 1291\n",
      "1040 / 1291\n",
      "1060 / 1291\n",
      "1080 / 1291\n",
      "1100 / 1291\n",
      "1120 / 1291\n",
      "1140 / 1291\n",
      "1160 / 1291\n",
      "1180 / 1291\n",
      "1200 / 1291\n",
      "1220 / 1291\n",
      "1240 / 1291\n",
      "1260 / 1291\n",
      "1280 / 1291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18397.111409629724"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model2, \"Electron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
