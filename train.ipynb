{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we will conduct all of our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Using cached nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.dataloading.pytorch import GraphDataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import nbimporter\n",
    "import dataset as ds\n",
    "import model as mfile\n",
    "from score import test\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds.SyntheticDataset()\n",
    "batch_size = 1\n",
    "\n",
    "# We want batch size to be 1 because do not want batched graphs (as this is not the correct structure of our individual molecules)\n",
    "train_dataloader = GraphDataLoader(train_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from os.path import exists\n",
    "\n",
    "def train(model, epochs, file_name='SavedModels/electron.pth', output=False, debug_batch_interval=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    \n",
    "    # Try to load best_mae\n",
    "    best_mae = None\n",
    "    if exists('SavedModels/bestmae.txt'):\n",
    "        with open('SavedModels/bestmae.txt', 'r') as f:\n",
    "            best_mae = float(f.read())\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), position=0, desc=\"Epochs\"):\n",
    "        \n",
    "        running, batch_running, ct, batch_ct = 0, 0, 0, 0\n",
    "        print('Epoch', epoch+1)\n",
    "        for batch_idx, (graph, label) in tqdm(enumerate(train_dataloader), position=1, desc=\"Batches\", total=len(train_dataloader) * batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            bf = graph.edata['bond_feats'].float()\n",
    "            af = graph.ndata['atom_feats'].float()\n",
    "            y_pred = model(graph, af, bf)\n",
    "            \n",
    "#             if y_pred.item() == 0:\n",
    "#                 print(batch_idx, \"pred = 0\")\n",
    "#             if y_pred.item() == 0 and len(DEBUG_PREDS) > 5 and sum(DEBUG_PREDS[-5:-1]) == 0:\n",
    "#                 print(\"Cut\")\n",
    "#                 return\n",
    "            \n",
    "            # The 23.06 is the same value used in score.py (conversion to kcal/mol)\n",
    "            # L1 is MAE, L2 is MSE\n",
    "            loss = torch.nn.functional.l1_loss(y_pred.reshape(1), label) * 23.06 # ((y_pred.reshape(1,-1) - batch_y)**2).sum()\n",
    "            running += loss.item()\n",
    "            batch_running += loss.item()\n",
    "            ct += 1\n",
    "            batch_ct += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Every debug_batch_interval iterations, print the data we've churned through (iterations * data per batch)\n",
    "            if output and batch_idx % (len(train_dataloader) // debug_batch_interval) == 0:                \n",
    "                print('Epoch: {} [{}/{} ({:.0f}%)]\\tBatch Loss: {:.2f}\\tEpoch Loss: {:.2f}'.format(\n",
    "                          epoch+1, batch_idx, len(train_dataloader) * batch_size,    # current sample num / total num\n",
    "                          100. * batch_idx / len(train_dataloader), # this batch num's % of total dataset\n",
    "                          batch_running // batch_ct, # the loss for this batch\n",
    "                          running // ct) # running loss for the epoch\n",
    "                     )\n",
    "                batch_running, batch_ct = 0, 0\n",
    "                \n",
    "        this_loss = running / ct\n",
    "        if output:\n",
    "            print(\"\\nAverage Loss:\", round(running / ct * 100) / 100.0,\"\\n\")\n",
    "        else:\n",
    "            print(\"Epoch\", epoch+1, \"Average Loss:\", round(this_loss * 100) / 100.0)\n",
    "            \n",
    "        # Save our model\n",
    "        if not best_mae:\n",
    "            best_mae = this_loss\n",
    "            checkpoint = {'state_dict': model.state_dict(),'optimizer': optimizer.state_dict()}\n",
    "            torch.save(checkpoint, file_name)\n",
    "        if this_loss < best_mae:\n",
    "            best_mae = this_loss\n",
    "            print(\"New best model found! Saving with loss of\", best_mae)\n",
    "            \n",
    "            # Write our best mae so we can keep track every time we retrain\n",
    "            with open('SavedModels/bestmae.txt', 'w') as f:\n",
    "                f.write(str(best_mae))\n",
    "            checkpoint = {'state_dict': model.state_dict(),'optimizer': optimizer.state_dict()}\n",
    "            torch.save(checkpoint, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 11 (node), 5 (edge)\n"
     ]
    }
   ],
   "source": [
    "# All graphs in the list have the same scheme size, so pull the dimensions from the first\n",
    "node_dim = train_dataset[0][0].ndata['atom_feats'].shape[1]\n",
    "edge_dim = train_dataset[0][0].edata['bond_feats'].shape[1]\n",
    "print(\"Dimensions:\", node_dim, \"(node),\", edge_dim, \"(edge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgllife\n",
    "model = mfile.Electron_MPNN(node_dim, edge_dim)\n",
    "# Attempt to load model if electron_mpnn.pth exists (check with os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Description: \\\n",
    "Our model follows a similar architecture as the MPNN model. It consists of a two linear layers (one at the front, one at the end), a convolution layer, and a GRU layer.\n",
    "\n",
    "- **fc1**: This linear + relu is our first \"line of attack,\" looking for connectings between our data before we lose information on individual atoms via convolution\n",
    "- **gnn_layer**: This layer uses convolution involving two hidden layers to try and grab information about neighbors in an efficient manner\n",
    "- **gru**: To be completely honest, I am not entirely sure I understand GRUs. My only understanding of it is that it serves to eliminate the issue of the vanishing gradient which we could expect to stumble upon after our fc1 and gnn layers. We are experimenting with getting rid of it to better understand its impact\n",
    "- ~~**fc2**: This fully-connected layer serves as our final decision maker, projecting back into 1 dimension (granted there is only 1 dimension at this point anyways) and trying to making sense of the previously convoluted data~~\n",
    "\n",
    "Some of the most important modifications of this model which differentiates it from the MPNN model stems from the negative min_PE output labels. For this reason, many Relu's were stripped from the model, both in the architecture itself and in the forward passes. I experimented with a linear \"decision\" layer at the very end, but this caused the model to try to make an approximation of the output labels which would end up with the average of the output labels (minimizing error with a constant). As you can imagine, this is unideal, so we ended up scrapping this idea.\n",
    "\n",
    "Training Description: \\\n",
    "To train, I have found that after about 8 epochs, the model begins to stablize. So, the training scheme is planned as follows:\n",
    "\n",
    "- 8 epochs w/ Adam opt @ 0.1\n",
    "- 8 epochs w/ Adam opt @ 0.01\n",
    "\n",
    "This is to help refine the smaller details of the gradient with respect to the weights in our model. This is essentially our own version of momentum because we try to have the model drop mae rather quickly, and then be refined with minute changes in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electron_MPNN(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=11, out_features=1, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (gnn_layer): NNConv(\n",
      "    (edge_func): Sequential(\n",
      "      (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9551ae685645d5b5a48a11831243de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf44ef3cf7a541f1820daaf124946eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [0/1210 (0%)]\tBatch Loss: 87088.00\tEpoch Loss: 87088.00\n",
      "Epoch: 1 [242/1210 (20%)]\tBatch Loss: 29882.00\tEpoch Loss: 30117.00\n",
      "Epoch: 1 [484/1210 (40%)]\tBatch Loss: 14342.00\tEpoch Loss: 22246.00\n",
      "Epoch: 1 [726/1210 (60%)]\tBatch Loss: 12578.00\tEpoch Loss: 19028.00\n",
      "Epoch: 1 [968/1210 (80%)]\tBatch Loss: 12072.00\tEpoch Loss: 17291.00\n",
      "\n",
      "Average Loss: 16269.84 \n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c27802ca5224d819d35fb06e0d82e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 [0/1210 (0%)]\tBatch Loss: 8533.00\tEpoch Loss: 8533.00\n",
      "Epoch: 2 [242/1210 (20%)]\tBatch Loss: 12043.00\tEpoch Loss: 12029.00\n",
      "Epoch: 2 [484/1210 (40%)]\tBatch Loss: 13064.00\tEpoch Loss: 12545.00\n",
      "Epoch: 2 [726/1210 (60%)]\tBatch Loss: 11804.00\tEpoch Loss: 12298.00\n",
      "Epoch: 2 [968/1210 (80%)]\tBatch Loss: 12061.00\tEpoch Loss: 12239.00\n",
      "\n",
      "Average Loss: 12308.54 \n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7af1ae76084631be2d378c1b422100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 [0/1210 (0%)]\tBatch Loss: 1008.00\tEpoch Loss: 1008.00\n",
      "Epoch: 3 [242/1210 (20%)]\tBatch Loss: 13181.00\tEpoch Loss: 13131.00\n",
      "Epoch: 3 [484/1210 (40%)]\tBatch Loss: 11758.00\tEpoch Loss: 12446.00\n",
      "Epoch: 3 [726/1210 (60%)]\tBatch Loss: 12244.00\tEpoch Loss: 12379.00\n",
      "Epoch: 3 [968/1210 (80%)]\tBatch Loss: 11530.00\tEpoch Loss: 12167.00\n",
      "\n",
      "Average Loss: 12205.47 \n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bf2e757c2a4bb1bc1b82c5d2549031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 [0/1210 (0%)]\tBatch Loss: 19923.00\tEpoch Loss: 19923.00\n",
      "Epoch: 4 [242/1210 (20%)]\tBatch Loss: 12142.00\tEpoch Loss: 12174.00\n",
      "Epoch: 4 [484/1210 (40%)]\tBatch Loss: 13426.00\tEpoch Loss: 12799.00\n",
      "Epoch: 4 [726/1210 (60%)]\tBatch Loss: 11271.00\tEpoch Loss: 12290.00\n",
      "Epoch: 4 [968/1210 (80%)]\tBatch Loss: 11989.00\tEpoch Loss: 12215.00\n",
      "\n",
      "Average Loss: 12392.66 \n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a993ee6ea94aed986098552d656e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 [0/1210 (0%)]\tBatch Loss: 1190.00\tEpoch Loss: 1190.00\n",
      "Epoch: 5 [242/1210 (20%)]\tBatch Loss: 12430.00\tEpoch Loss: 12384.00\n",
      "Epoch: 5 [484/1210 (40%)]\tBatch Loss: 12324.00\tEpoch Loss: 12354.00\n",
      "Epoch: 5 [726/1210 (60%)]\tBatch Loss: 11926.00\tEpoch Loss: 12212.00\n",
      "Epoch: 5 [968/1210 (80%)]\tBatch Loss: 11608.00\tEpoch Loss: 12061.00\n",
      "\n",
      "Average Loss: 12071.68 \n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a91d90bacf4eb283ffeabefaf44389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 [0/1210 (0%)]\tBatch Loss: 19554.00\tEpoch Loss: 19554.00\n",
      "Epoch: 6 [242/1210 (20%)]\tBatch Loss: 12950.00\tEpoch Loss: 12977.00\n",
      "Epoch: 6 [484/1210 (40%)]\tBatch Loss: 11913.00\tEpoch Loss: 12446.00\n",
      "Epoch: 6 [726/1210 (60%)]\tBatch Loss: 12754.00\tEpoch Loss: 12548.00\n",
      "Epoch: 6 [968/1210 (80%)]\tBatch Loss: 11361.00\tEpoch Loss: 12252.00\n",
      "\n",
      "Average Loss: 12293.76 \n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35958f3c07cf45b58b9a62cd411bd1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 [0/1210 (0%)]\tBatch Loss: 5.00\tEpoch Loss: 5.00\n",
      "Epoch: 7 [242/1210 (20%)]\tBatch Loss: 11690.00\tEpoch Loss: 11642.00\n",
      "Epoch: 7 [484/1210 (40%)]\tBatch Loss: 11791.00\tEpoch Loss: 11716.00\n",
      "Epoch: 7 [726/1210 (60%)]\tBatch Loss: 12111.00\tEpoch Loss: 11848.00\n",
      "Epoch: 7 [968/1210 (80%)]\tBatch Loss: 12279.00\tEpoch Loss: 11955.00\n",
      "\n",
      "Average Loss: 12125.23 \n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d5e2e5c25f49d28bdc70e3352d8f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 [0/1210 (0%)]\tBatch Loss: 22302.00\tEpoch Loss: 22302.00\n",
      "Epoch: 8 [242/1210 (20%)]\tBatch Loss: 12341.00\tEpoch Loss: 12382.00\n",
      "Epoch: 8 [484/1210 (40%)]\tBatch Loss: 12273.00\tEpoch Loss: 12328.00\n",
      "Epoch: 8 [726/1210 (60%)]\tBatch Loss: 12083.00\tEpoch Loss: 12247.00\n",
      "Epoch: 8 [968/1210 (80%)]\tBatch Loss: 12064.00\tEpoch Loss: 12201.00\n",
      "\n",
      "Average Loss: 12028.69 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, 8, output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = {'state_dict': model.state_dict()}\n",
    "# torch.save(checkpoint, \"electron_mpnn_no_ReLU.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = mfile.Electron_MPNN(node_dim, edge_dim, out_dim=1)\n",
    "best_model.load_state_dict(torch.load(\"electron_mpnn_v1_ReLU.pth\")[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1458.2877]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
