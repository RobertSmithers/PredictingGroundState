{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we will define our model and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "\n",
    "Finally, you should have at least one notebook where you define and train your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template taken from https://docs.dgl.ai/tutorials/blitz/6_load_data.html#sphx-glr-tutorials-blitz-6-load-data-py\n",
    "class SyntheticDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='synthetic')\n",
    "\n",
    "    def process(self):\n",
    "        edges = pd.read_csv('./graph_edges.csv')\n",
    "        properties = pd.read_csv('./graph_properties.csv')\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Convert the label list to tensor for saving.\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "dataset = SyntheticDataset()\n",
    "graph, label = dataset[0]\n",
    "print(graph, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class ElectronConv(nn.Module):\n",
    "    \"\"\"Graph convolution module used by the GraphElectron model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat : int\n",
    "        Input feature size.\n",
    "    out_feat : int\n",
    "        Output feature size.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(ElectronConv, self).__init__()\n",
    "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
    "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        \"\"\"Forward computation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : Graph\n",
    "            The input graph.\n",
    "        h : Tensor\n",
    "            The input node feature.\n",
    "        \"\"\"\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # update_all is a message passing API.\n",
    "            g.update_all(message_func=fn.copy_u('h', 'm'), reduce_func=fn.mean('m', 'h_N'))\n",
    "            h_N = g.ndata['h_N']\n",
    "            h_total = torch.cat([h, h_N], dim=1)\n",
    "            return self.linear(h_total)\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = ElectronConv(in_feats, h_feats)\n",
    "        self.conv2 = ElectronConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN_Rec(nn.Module):\n",
    "    \"\"\"MPNN.\n",
    "\n",
    "    MPNN is introduced in `Neural Message Passing for Quantum Chemistry\n",
    "    <https://arxiv.org/abs/1704.01212>`__.\n",
    "\n",
    "    This class performs message passing in MPNN and returns the updated node representations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_in_feats : int\n",
    "        Size for the input node features.\n",
    "    node_out_feats : int\n",
    "        Size for the output node representations. Default to 64.\n",
    "    edge_in_feats : int\n",
    "        Size for the input edge features. Default to 128.\n",
    "    edge_hidden_feats : int\n",
    "        Size for the hidden edge representations.\n",
    "    num_step_message_passing : int\n",
    "        Number of message passing steps. Default to 6.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=64,\n",
    "                 edge_hidden_feats=128, num_step_message_passing=6):\n",
    "        super(MPNN_Rec, self).__init__()\n",
    "\n",
    "        self.project_node_feats = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, node_out_feats),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.num_step_message_passing = num_step_message_passing\n",
    "        edge_network = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats)\n",
    "        )\n",
    "        self.gnn_layer = NNConv(\n",
    "            in_feats=node_out_feats,\n",
    "            out_feats=node_out_feats,\n",
    "            edge_func=edge_network,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "        self.gru = nn.GRU(node_out_feats, node_out_feats)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize model parameters.\"\"\"\n",
    "        self.project_node_feats[0].reset_parameters()\n",
    "        self.gnn_layer.reset_parameters()\n",
    "        for layer in self.gnn_layer.edge_func:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.reset_parameters()\n",
    "        self.gru.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        \"\"\"Performs message passing and updates node representations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : DGLGraph\n",
    "            DGLGraph for a batch of graphs.\n",
    "        node_feats : float32 tensor of shape (V, node_in_feats)\n",
    "            Input node features. V for the number of nodes in the batch of graphs.\n",
    "        edge_feats : float32 tensor of shape (E, edge_in_feats)\n",
    "            Input edge features. E for the number of edges in the batch of graphs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node_feats : float32 tensor of shape (V, node_out_feats)\n",
    "            Output node representations.\n",
    "        \"\"\"\n",
    "        node_feats = self.project_node_feats(node_feats) # (V, node_out_feats)\n",
    "        hidden_feats = node_feats.unsqueeze(0)           # (1, V, node_out_feats)\n",
    "\n",
    "        for _ in range(self.num_step_message_passing):\n",
    "            node_feats = F.relu(self.gnn_layer(g, node_feats, edge_feats))\n",
    "            node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "            node_feats = node_feats.squeeze(0)\n",
    "\n",
    "        return node_feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
