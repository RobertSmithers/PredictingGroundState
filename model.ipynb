{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we will define our model and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: \n",
    "\n",
    "Finally, you should have at least one notebook where you define and train your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.data.utils import save_graphs, load_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn.pytorch import NNConv\n",
    "from dgl.nn.pytorch import TAGConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ronan make your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RJ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to experiment with: SumPooling layer? Kind of like a conv, can sum up neighbors and find important structural properties of molecule\n",
    "# from dgl.nn import SumPooling\n",
    "\n",
    "# Also a good read here (https://arxiv.org/pdf/1710.10370.pdf) on Topology Adaptive Graph Convolutional layer might be useful.\n",
    "# From my takeaways, we can use this \"topology\" to better track/weight the important parts of the structure\n",
    "# (maybe the center of the molecule is important, or specific edge portions of the molecule) TAG can find this\n",
    "\n",
    "# SAGEConv\n",
    "\n",
    "# Ultimately, the NNConv layer, as used in the MPNN model, is the best one for this situation.\n",
    "# We have come to this conclusion after trying various other convolution modules\n",
    "# and finally reading up on this paper which relates closely to what we are doing (https://arxiv.org/pdf/1704.01212.pdf)\n",
    "# (Quantum Chemistry computations)\n",
    "\n",
    "# Note they used GatedGraphConv first and that worked okay but not as well as NNConv... we could look to backtrack to GGC\n",
    "class Electron_MPNN(nn.Module):\n",
    "    def __init__(self, node_in_feats, edge_in_feats, node_out_feats=64,\n",
    "                 edge_hidden_feats=128, message_passing_steps=6):\n",
    "        super(Electron_MPNN, self).__init__()\n",
    "\n",
    "        # Projection\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(node_in_feats, node_out_feats),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        # Multi-iteration Convolution\n",
    "        self.message_passing_steps = message_passing_steps\n",
    "        edge_func = nn.Sequential(\n",
    "            nn.Linear(edge_in_feats, edge_hidden_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(edge_hidden_feats, node_out_feats * node_out_feats)\n",
    "        )\n",
    "        \n",
    "        self.gnn_layer = NNConv(\n",
    "            in_feats=node_out_feats,\n",
    "            out_feats=node_out_feats,\n",
    "            edge_func=edge_func,\n",
    "            aggregator_type='sum'\n",
    "        )\n",
    "        \n",
    "        # GRU used in MPNN to get rid of vanishing gradient on Conv layer\n",
    "        # However, I think it is just added complexity to our model, so we will keep it here for reference but not use it\n",
    "        self.gru = nn.GRU(node_out_feats, node_out_feats)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(out_dim, out_dim)\n",
    "\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        node_feats = self.fc1(node_feats) # (V, node_out_feats)\n",
    "        \n",
    "        hidden_feats = node_feats.unsqueeze(0)           # (1, V, node_out_feats)\n",
    "\n",
    "#         node_feats = self.gnn_layer(g, node_feats, edge_feats)\n",
    "        \n",
    "        for _ in range(self.message_passing_steps):\n",
    "            node_feats = self.gnn_layer(g, node_feats, edge_feats)\n",
    "            # GRU requires 3 dimensions\n",
    "            node_feats, hidden_feats = self.gru(node_feats.unsqueeze(0), hidden_feats)\n",
    "            node_feats = node_feats.squeeze(0)\n",
    "            \n",
    "#         node_feats = self.fc2(node_feats)\n",
    "#         print(node_feats)\n",
    "#         print(\"last_layer\", node_feats)\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import Set2Set\n",
    "class MPNNPredictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_in_feats,\n",
    "                 edge_in_feats,\n",
    "                 node_out_feats=64,\n",
    "                 edge_hidden_feats=128,\n",
    "                 n_tasks=1,\n",
    "                 num_step_set2set=6,\n",
    "                 num_layer_set2set=3,\n",
    "                 message_passing_steps=6):\n",
    "        super(MPNNPredictor, self).__init__()\n",
    "\n",
    "        self.gnn = Electron_MPNN(node_in_feats=node_in_feats,\n",
    "                                 node_out_feats=node_out_feats,\n",
    "                                 edge_in_feats=edge_in_feats,\n",
    "                                 edge_hidden_feats=edge_hidden_feats,\n",
    "                                 message_passing_steps=message_passing_steps\n",
    "                                )\n",
    "                    \n",
    "        self.readout = Set2Set(input_dim=node_out_feats,\n",
    "                               n_iters=num_step_set2set,\n",
    "                               n_layers=num_layer_set2set)\n",
    "        \n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(node_out_feats, n_tasks)\n",
    "        )\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
    "        graph_feats = self.readout(g, node_feats)\n",
    "        return self.predict(graph_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the graphs to get dimensions for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, _ = load_graphs(\"./DataGraphs/data_F_graph.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 11 (node), 5 (edge)\n"
     ]
    }
   ],
   "source": [
    "# All graphs in the list have the same scheme size, so pull the dimensions from the first\n",
    "node_dim = graphs[0].ndata['atom_feats'].shape[1]\n",
    "edge_dim = graphs[0].edata['bond_feats'].shape[1]\n",
    "print(\"Dimensions:\", node_dim, \"(node),\", edge_dim, \"(edge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MPNNPredictor(node_dim, edge_dim)\n",
    "#model = Electron_MPNN(node_dim, edge_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = graphs[1]\n",
    "edges = sample_data.edata['bond_feats'].float()\n",
    "nodes = sample_data.ndata['atom_feats'].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1101]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_data, nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490.814183533093\n",
      "11490.814183533093\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "if exists('SavedModels/bestmae.txt'):\n",
    "    with open('SavedModels/bestmae.txt', 'r') as f:\n",
    "        txt = f.read()\n",
    "        print(txt)\n",
    "        print(float(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mae = 123879.123\n",
    "with open('SavedModels/bestmae.txt', 'w') as f:\n",
    "    f.write(str(best_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
